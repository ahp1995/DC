{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from operations import *\n",
    "from torch.autograd import Variable\n",
    "from utils import drop_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(nn.Module):\n",
    "    def __init__(self, genotype, C_prev_prev, C_prev, C, reduction, reduction_prev):\n",
    "        super(Cell, self).__init__()\n",
    "        print(C_prev_prev, C_prev, C)\n",
    "        \n",
    "        if reduction_prev:\n",
    "            self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n",
    "        else:\n",
    "            self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0)\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0)\n",
    "        \n",
    "        if reduction:\n",
    "            op_names, indices = zip(*genotype.reduce)\n",
    "            concat = genotype.reduce_concat\n",
    "        else:\n",
    "            op_names, indices = zip(*genotype.normal)\n",
    "            concat = genotype.normal_concat\n",
    "        self._compile(C, op_names, indices, concat, reduction)\n",
    "        \n",
    "    def _compile(self, C, op_names, indices, concat, reduction):\n",
    "        assert len(op_names) == len(indices)\n",
    "        self._steps = len(op_names) // 2\n",
    "        self._concat = concat\n",
    "        self.multiplier = len(concat)\n",
    "        \n",
    "        self._ops = nn.ModuleList()\n",
    "        for name, index in zip(op_names, indices):\n",
    "            stride = 2 if reduction and index < 2 else 1\n",
    "            op = OPS[name](C, stride, True)\n",
    "            self._ops += [op]\n",
    "        self._indices = indices\n",
    "        \n",
    "    def forward(self, s0, s1, drop_prob):\n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "        \n",
    "        states = [s0, s1]\n",
    "        for i in range(self._steps):\n",
    "            h1 = states[self._indices[2*i]]\n",
    "            h2 = states[self._indices[2*i+1]]\n",
    "            op1 = self._ops[2*i]\n",
    "            op2 = self._ops[2*i+1]\n",
    "            h1 = op1(h1)\n",
    "            h2 = op2(h2)\n",
    "            if self.training and drop_prob > 0.:\n",
    "                if not isinstance(op1, Identity):\n",
    "                    h1 = drop_path(h1, drop_prob)\n",
    "                if not isinstance(op2, Identity):\n",
    "                    h2 = drop_path(h1, drop_prob)\n",
    "            s = h1 + h2\n",
    "            states += [s]\n",
    "        return torch.cat([states[i] for i in self._concat], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryHeadCIFAR(nn.Module):\n",
    "    def __init__(self, C, num_classes):\n",
    "        \"\"\"assuming input size 8x8\"\"\"\n",
    "        super(AuxiliaryHeadCIFAR, self).__init__()\n",
    "        sefl.features = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(5, stride=3, padding=0, count_include_pad=False),\n",
    "            nn.Conv2d(C, 128, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 768, 2, bias=False),\n",
    "            nn.BatchNorm2d(768),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.classifier = nn.Linear(768, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x.view(x.size(0), -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkCIFAR(nn.Module):\n",
    "    def __init__(self, C, num_classes, layers, auxiliary, genotype):\n",
    "        super(NetworkCIFAR, self).__init__()\n",
    "        self._layers = layers\n",
    "        self._auxiliary = auxiliary\n",
    "        \n",
    "        stem_multiplier = 3\n",
    "        C_curr = stem_multiplier*C\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, C_curr, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(C_curr)\n",
    "        )\n",
    "        \n",
    "        C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "        self.cells = nn.ModuleList()\n",
    "        reduction_prev = False\n",
    "        for i in range(layers):\n",
    "            if i in [layers//3, 2*layers//3]:\n",
    "                C_curr *= 2\n",
    "                reduction = True\n",
    "            else:\n",
    "                reduction = False\n",
    "            cell = Cell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n",
    "            reduction_prev = reduction\n",
    "            self.cells += [cell]\n",
    "            C_prev_prev, C_prev = C_prev, cell.multiplier*C_curr\n",
    "            if i == 2*layers//3:\n",
    "                C_to_auxiliary = C_prev\n",
    "                \n",
    "        if auxiliary:\n",
    "            self.auxiliary_head = AuxiliaryHeadCIFAR(C_to_auxiliary, num_classes)\n",
    "        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(C_prev, num_classes)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        logits_aux = None\n",
    "        s0 = s1 = self.stem(input)\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            s0, s1 = s1, cell(s0, s1, 0.2)\n",
    "            if i == 2*self._layers//3:\n",
    "                if self._auxiliary and self.training:\n",
    "                    logits_aux = self.auxiliary_head(s1)\n",
    "        out = self.global_pooling(s1)\n",
    "        logits = self.classifier(out.view(out.size(0),-1))\n",
    "        return logits, logits_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 3\n",
      "9 12 3\n",
      "12 12 3\n",
      "12 12 3\n",
      "12 12 3\n",
      "12 12 3\n",
      "12 12 6\n",
      "12 24 6\n",
      "24 24 6\n",
      "24 24 6\n",
      "24 24 6\n",
      "24 24 6\n",
      "24 24 6\n",
      "24 24 12\n",
      "24 48 12\n",
      "48 48 12\n",
      "48 48 12\n",
      "48 48 12\n",
      "48 48 12\n",
      "48 48 12\n",
      "torch.Size([1, 3, 32, 32])\n",
      "(tensor([[-0.0275,  0.0313,  0.1053,  0.0494,  0.0683,  0.0748, -0.0997,  0.1292,\n",
      "         -0.0196, -0.0119]], device='cuda:0', grad_fn=<AddmmBackward0>), None)\n"
     ]
    }
   ],
   "source": [
    "import genotypes\n",
    "arch = 'DARTS'\n",
    "drop_path_prob = 0.2\n",
    "genotype = eval(\"genotypes.%s\"% arch)\n",
    "device = 'cuda'\n",
    "# print(genotype)\n",
    "model = NetworkCIFAR(3, 10, 20, False, genotype).to(device)\n",
    "# print(model)\n",
    "input = torch.randn([1, 3, 32, 32]).to(device)\n",
    "print(input.shape)\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
